// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go_gapic. DO NOT EDIT.

// [START aiplatform_v1beta1_generated_JobService_CreateBatchPredictionJob_sync]

package main

import (
	"context"

	aiplatformpb "cloud.google.com/go/aiplatform/apiv1beta1/aiplatformpb"
)

func main() {
	ctx := context.Background()
	// This snippet has been automatically generated and should be regarded as a code template only.
	// It will require modifications to work:
	// - It may require correct/in-range values for request initialization.
	// - It may require specifying regional endpoints when creating the service client as shown in:
	//   https://pkg.go.dev/cloud.google.com/go#hdr-Client_Options
	c, err := aiplatformpb.NewJobClient(ctx)
	if err != nil {
		// TODO: Handle error.
	}
	defer c.Close()

	// TODO: Fill request struct fields.
	// See https://pkg.go.dev/cloud.google.com/go/aiplatform/apiv1beta1/aiplatformpb#CreateBatchPredictionJobRequest.
	req := &aiplatformpb.CreateBatchPredictionJobRequest{
		Parent: "",
		BatchPredictionJob: &aiplatformpb.BatchPredictionJob{
			Name: "",
			DisplayName: "",
			Model: "",
			ModelVersionId: "",
			UnmanagedContainerModel: &aiplatformpb.UnmanagedContainerModel{
				ArtifactUri: "",
				PredictSchemata: &aiplatformpb.PredictSchemata{...}
				ContainerSpec: &aiplatformpb.ModelContainerSpec{...}
			}
			InputConfig: "",
			InstanceConfig: "",
			ModelParameters: &aiplatformpb.Value{
				IntValue: "",
				DoubleValue: "",
				StringValue: "",
			}
			OutputConfig: "",
			DedicatedResources: &aiplatformpb.BatchDedicatedResources{
				MachineSpec: &aiplatformpb.MachineSpec{...}
				StartingReplicaCount: "",
				MaxReplicaCount: "",
			}
			ServiceAccount: "",
			ManualBatchTuningParameters: &aiplatformpb.ManualBatchTuningParameters{
				BatchSize: "",
			}
			GenerateExplanation: "",
			ExplanationSpec: &aiplatformpb.ExplanationSpec{
				Parameters: &aiplatformpb.ExplanationParameters{...}
				Metadata: &aiplatformpb.ExplanationMetadata{...}
			}
			OutputInfo: "",
			State: "",
			Error: &statuspb.Status{
				Code: "",
				Message: "",
				Details: &anypb.Any{...}
			}
			PartialFailures: &statuspb.Status{
				Code: "",
				Message: "",
				Details: &anypb.Any{...}
			}
			ResourcesConsumed: &aiplatformpb.ResourcesConsumed{
				ReplicaHours: "",
			}
			CompletionStats: &aiplatformpb.CompletionStats{
				SuccessfulCount: "",
				FailedCount: "",
				IncompleteCount: "",
				SuccessfulForecastPointCount: "",
			}
			CreateTime: &timestamppb.Timestamp{
				Seconds: "",
				Nanos: "",
			}
			StartTime: &timestamppb.Timestamp{
				Seconds: "",
				Nanos: "",
			}
			EndTime: &timestamppb.Timestamp{
				Seconds: "",
				Nanos: "",
			}
			UpdateTime: &timestamppb.Timestamp{
				Seconds: "",
				Nanos: "",
			}
			Labels: "",
			EncryptionSpec: &aiplatformpb.EncryptionSpec{
				KmsKeyName: "",
			}
			ModelMonitoringConfig: &aiplatformpb.ModelMonitoringConfig{
				ObjectiveConfigs: &aiplatformpb.ModelMonitoringObjectiveConfig{...}
				AlertConfig: &aiplatformpb.ModelMonitoringAlertConfig{...}
				AnalysisInstanceSchemaUri: "",
				StatsAnomaliesBaseDirectory: &aiplatformpb.GcsDestination{...}
			}
			ModelMonitoringStatsAnomalies: &aiplatformpb.ModelMonitoringStatsAnomalies{
				Objective: "",
				DeployedModelId: "",
				AnomalyCount: "",
				FeatureStats: "",
			}
			ModelMonitoringStatus: &statuspb.Status{
				Code: "",
				Message: "",
				Details: &anypb.Any{...}
			}
			DisableContainerLogging: "",
		}
	}
	resp, err := c.CreateBatchPredictionJob(ctx, req)
	if err != nil {
		// TODO: Handle error.
	}
	// TODO: Use resp.
	_ = resp
}

// [END aiplatform_v1beta1_generated_JobService_CreateBatchPredictionJob_sync]
